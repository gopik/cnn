{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "sys.path.append('..')\n",
    "import string\n",
    "import recognizer\n",
    "import tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create translation maxtrix (to shift the image right by 6 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_matrix = np.float32(np.array([1, 0, 5, 0, 1, 0]).reshape(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation of pixels from out of the image into image causes black pixels. Hence compute the inverse of the black filters by tranlating a white image and inverting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def translate_image(src_path):\n",
    "    img = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "    white_mask = cv2.warpAffine(np.ones_like(img) * 255, tx_matrix, dsize=(img.shape[1], img.shape[0]))\n",
    "    white_mask = 255 - white_mask\n",
    "\n",
    "    img = cv2.warpAffine(img, tx_matrix, dsize=(img.shape[1], img.shape[0]))\n",
    "    img += white_mask\n",
    "    cv2.imwrite(src_path, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_font_png = tmp.recursive_find_files('../fonts', '.*png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in list_font_png:\n",
    "    translate_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=False,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "for path in list_font_png:\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    cat = os.path.basename(os.path.dirname(path))\n",
    "    x = img\n",
    "    x = x[np.newaxis, :, :, np.newaxis]\n",
    "    i = 0\n",
    "    target_dir = os.path.join('/home/gopik/github/cnn/fonts/train', cat)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "    for batch in datagen.flow(x, ['0'], batch_size=1,   shuffle=True):\n",
    "        aug_img = batch[0][0].reshape(40, 30)\n",
    "        i += 1\n",
    "        if i > 1000:\n",
    "            break  # otherwise the generator would loop indefinitely\n",
    "        \n",
    "        file_path = os.path.join(target_dir, str(i) + '.jpeg')\n",
    "        cv2.imwrite(file_path , aug_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "path = '/home/gopik/github/cnn/fonts/train/labels.txt'\n",
    "def write_labels(path):\n",
    "    labels = string.digits + string.ascii_uppercase\n",
    "    with open(path, 'w') as f:\n",
    "        for l in labels:\n",
    "            f.write(l)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lot1_files = tmp.recursive_find_files('../data/lot1', '.*recog.*jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = pd.Series(lot1_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basename = s.apply(lambda p: os.path.basename(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = basename.str.split('_').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'path': path, 'basename': basename, 'cat':cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def copy_file(base, cat, src):\n",
    "    target_dir = os.path.join(base, cat)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "    dst = os.path.join(target_dir, os.path.basename(src))\n",
    "    copyfile(dst=dst, src=src)\n",
    "    \n",
    "df = df.apply(lambda row: copy_file('/home/gopik/github/cnn/data/lot1/train', row['cat'], row['path']), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_matrix = np.array([1, 0, 6, 0, 1, 1]).reshape(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_tx = cv2.warpAffine(img, np.float32(tx_matrix), dsize=(img.shape[1], img.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in string.ascii_uppercase + string.digits:\n",
    "    target_dir = os.path.join('/home/gopik/github/cnn/fonts/arial_35/', c)\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "    if not os.path.exists(target_dir + \"/\" + c + \".png\"):\n",
    "        shutil.move('/home/gopik/github/cnn/fonts/arial_35/' + c + '.png', target_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function resize:\n",
      "\n",
      "resize(...)\n",
      "    resize(src, dsize[, dst[, fx[, fy[, interpolation]]]]) -> dst\n",
      "    .   @brief Resizes an image.\n",
      "    .   \n",
      "    .   The function resize resizes the image src down to or up to the specified size. Note that the\n",
      "    .   initial dst type or size are not taken into account. Instead, the size and type are derived from\n",
      "    .   the `src`,`dsize`,`fx`, and `fy`. If you want to resize src so that it fits the pre-created dst,\n",
      "    .   you may call the function as follows:\n",
      "    .   @code\n",
      "    .   // explicitly specify dsize=dst.size(); fx and fy will be computed from that.\n",
      "    .   resize(src, dst, dst.size(), 0, 0, interpolation);\n",
      "    .   @endcode\n",
      "    .   If you want to decimate the image by factor of 2 in each direction, you can call the function this\n",
      "    .   way:\n",
      "    .   @code\n",
      "    .   // specify fx and fy and let the function compute the destination image size.\n",
      "    .   resize(src, dst, Size(), 0.5, 0.5, interpolation);\n",
      "    .   @endcode\n",
      "    .   To shrink an image, it will generally look best with cv::INTER_AREA interpolation, whereas to\n",
      "    .   enlarge an image, it will generally look best with cv::INTER_CUBIC (slow) or cv::INTER_LINEAR\n",
      "    .   (faster but still looks OK).\n",
      "    .   \n",
      "    .   @param src input image.\n",
      "    .   @param dst output image; it has the size dsize (when it is non-zero) or the size computed from\n",
      "    .   src.size(), fx, and fy; the type of dst is the same as of src.\n",
      "    .   @param dsize output image size; if it equals zero, it is computed as:\n",
      "    .   \\f[\\texttt{dsize = Size(round(fx*src.cols), round(fy*src.rows))}\\f]\n",
      "    .   Either dsize or both fx and fy must be non-zero.\n",
      "    .   @param fx scale factor along the horizontal axis; when it equals 0, it is computed as\n",
      "    .   \\f[\\texttt{(double)dsize.width/src.cols}\\f]\n",
      "    .   @param fy scale factor along the vertical axis; when it equals 0, it is computed as\n",
      "    .   \\f[\\texttt{(double)dsize.height/src.rows}\\f]\n",
      "    .   @param interpolation interpolation method, see cv::InterpolationFlags\n",
      "    .   \n",
      "    .   @sa  warpAffine, warpPerspective, remap\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tmp' from '../tmp.py'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tmp.Frame(orginal_dir_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_dir_list = map(lambda f: os.path.dirname(f), glob.glob(os.path.join('../data/lot1', '**/orginal.jpg'), recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_dir_list = list(orginal_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/lot1/outputs/new2/frames/1432',\n",
       " '../data/lot1/outputs/new2/frames/1481',\n",
       " '../data/lot1/outputs/new2/frames/1425',\n",
       " '../data/lot1/outputs/new2/frames/1478',\n",
       " '../data/lot1/outputs/new2/frames/1452']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orginal_dir_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'type' (pos 4) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-71cf6d288e6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_orig_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/cnn/tmp.py\u001b[0m in \u001b[0;36mget_orig_crop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mimg_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mimg_pad_resize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'type' (pos 4) not found"
     ]
    }
   ],
   "source": [
    "crops = f.get_orig_crop()\n",
    "k = list(crops)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function adaptiveThreshold:\n",
      "\n",
      "adaptiveThreshold(...)\n",
      "    adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst]) -> dst\n",
      "    .   @brief Applies an adaptive threshold to an array.\n",
      "    .   \n",
      "    .   The function transforms a grayscale image to a binary image according to the formulae:\n",
      "    .   -   **THRESH_BINARY**\n",
      "    .   \\f[dst(x,y) =  \\fork{\\texttt{maxValue}}{if \\(src(x,y) > T(x,y)\\)}{0}{otherwise}\\f]\n",
      "    .   -   **THRESH_BINARY_INV**\n",
      "    .   \\f[dst(x,y) =  \\fork{0}{if \\(src(x,y) > T(x,y)\\)}{\\texttt{maxValue}}{otherwise}\\f]\n",
      "    .   where \\f$T(x,y)\\f$ is a threshold calculated individually for each pixel (see adaptiveMethod parameter).\n",
      "    .   \n",
      "    .   The function can process the image in-place.\n",
      "    .   \n",
      "    .   @param src Source 8-bit single-channel image.\n",
      "    .   @param dst Destination image of the same size and the same type as src.\n",
      "    .   @param maxValue Non-zero value assigned to the pixels for which the condition is satisfied\n",
      "    .   @param adaptiveMethod Adaptive thresholding algorithm to use, see cv::AdaptiveThresholdTypes\n",
      "    .   @param thresholdType Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV,\n",
      "    .   see cv::ThresholdTypes.\n",
      "    .   @param blockSize Size of a pixel neighborhood that is used to calculate a threshold value for the\n",
      "    .   pixel: 3, 5, 7, and so on.\n",
      "    .   @param C Constant subtracted from the mean or weighted mean (see the details below). Normally, it\n",
      "    .   is positive but may be zero or negative as well.\n",
      "    .   \n",
      "    .   @sa  threshold, blur, GaussianBlur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.adaptiveThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cat, orig, img) = crops[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n"
     ]
    }
   ],
   "source": [
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(crops)[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3055f9a240>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAD8CAYAAAAys+slAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPZW4VwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3055eb7518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D 0\n",
      "U J\n",
      "6 8\n",
      "7 1\n",
      "4 4\n",
      "E L\n",
      "3 J\n",
      "9 3\n",
      "M 0\n",
      "2 2\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "for c, o, i in crops.values():\n",
    "    cl = predict_img(i)\n",
    "    print(c, cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_img = cv2.imread(k, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f30554ee8d0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAD8CAYAAAAys+slAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f305c0784e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(k_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f305554bc18>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAD8CAYAAAAys+slAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADbxJREFUeJzt3X+IHOd9x/HPx6p/4cRWhIQQ/lHZ\nqokxAqnlaqc0GFWui2SKZeFi4j+KCoakJoYI4hI5GKKiBmxIYv/REpw4qlWjWjFyZIng1haKTSqo\nVV9s1ZGsppZtiUicJYtEjn5AiqRv/9gRXG5mn5vd2dnd2Xu/4Ljd783uPHvio7nn2Z3vOCIEoNgl\ngx4AMMwICJBAQIAEAgIkEBAggYAACQQESCAgQEKlgNheYfsXtg/aXterQQHDwt2+k257lqT/lXSX\npCOS3pT0QES82+4xc+fOjYULF3a1P6CXDh06pBMnTni67X6vwj5uk3QwIj6QJNtbJK2S1DYgCxcu\n1Pj4eIVdAr0xNjZWarsqf2JdK+mXk+4fyWrAyKh9km77i7bHbY9//PHHde8O6KkqATkq6fpJ96/L\nar8jIr4XEWMRMTZv3rwKuwP6r0pA3pR0s+0bbV8m6QuSdvRmWMBw6HqSHhHnbD8s6RVJsyRtjIj9\nPRsZMASqrGIpIl6W9HKPxgIMHd5JBxIICJBAQIAEAgIkEBAggYAACQQESCAgQAIBARIICJBAQIAE\nAgIkEBAggYAACQQESCAgQAIBARIICJBAQICESuek2z4k6ZSk85LORUS5dnVAQ1QKSObPIuJED54H\nGDr8iQUkVA1ISHrV9s9sf7FoA1qPosmqBuTzEfFHklZK+rLtO6ZuQOtRNFmlgETE0ez7cUnb1Lok\nAjAyug6I7atsf/ribUl/IWlfrwYGDIMqq1jzJW2zffF5/jUi/r0nowKGRJXm1R9IWtLDsQBDh2Ve\nIIGAAAm9eCcdkoquFpzNzypti8HiCAIkEBAggYAACQQESCAgQMKMW8UqWkHqxeOLVqE62Vcnz9uJ\nulbXZspKHEcQIIGAAAkEBEggIEDCjJukV9XJRLSTbdtN0stO9Nvtq+p4qy5qNB1HECCBgAAJBARI\nICBAwrSTdNsbJf2lpOMRsTirzZH0Q0kLJR2SdH9E/Lq+YfZOJ5PW06dP52qbN28u/bztJrh33JHr\njqRbbrml9LjqeHe9U5283ia/w17mCPKspBVTausk7YqImyXtyu4DI2fagETETyX9akp5laRN2e1N\nku7t8biAodDtHGR+RExktz9SqwVQIVqPoskqT9Kj9Ydn2z9qaT2KJus2IMdsL5Ck7Pvx3g0JGB7d\nftRkh6Q1kh7Pvm/v2Yhq1skKzsmTJ3O1hx56qPTztlu9Wbcuv6axYcOGwm0vuaTc/2HtXtfKlStz\ntWPHjpV6TklavXp1Yf2xxx7L1Zq8WtXOtL99289L+k9Jn7V9xPaDagXjLtvvSfrz7D4wcqY9gkTE\nA21+dGePxwIMHd5JBxIICJAw484HGYZzHp566qlcrWjSK0lXXnllrlY03u3bi9dJdu/enaudOXOm\ncNui383YWPGFi8suHjTdzHiVQJcICJBAQIAEAgIkEBAgYcatYlXVi3aidYxh7969hduePXs2VxvF\nj4TUhSMIkEBAgAQCAiQQECCBSXqPXH311bnahQsXCrc9f/58rjYxMVGwpXTTTTflap1MsovG1e7M\nzvfff7/0884UHEGABAICJBAQIIGAAAllzknfaPu47X2TauttH7W9N/u6u95hAoNRZhXrWUn/KOlf\nptSfjIhv9XxEDXXnnflT9JctW1a47dq1a3O1J554onDbp59+Olf75JNPcrVXXnml8PHLly/P1dav\nX1+47ZIlSwrrM1m3rUeBGaHKHORh2+9kf4J9pmcjAoZItwH5rqRFkpZKmpD07XYb0psXTdZVQCLi\nWEScj4gLkr4v6bbEtvTmRWN19VET2wsmdXdfLWlfavuZqt0kvcjhw4cL66dOncrVii7s88YbbxQ+\n/r777svV9u0r/ufiPJG8MleYel7SMklzbR+R9A1Jy2wvVaur+yFJX6pxjMDAdNt69Ac1jAUYOryT\nDiQQECCBgAAJnDA1AEVdSXbu3Fm47Ycffpirbd26NVdr1yu36KStZ555ZrohIsMRBEggIEACAQES\nCAiQwCS9Ru1aj3ZyEZ+ibffv3196DDPlQjd14bcHJBAQIIGAAAkEBEggIEACq1g16uQEpKonK7Vb\nBXv00UdztUceeaSj55jJOIIACQQESCAgQEKZ1qPX237N9ru299v+SlafY3un7fey7/TGwsgpM0k/\nJ+mrEfGW7U9L+pntnZL+RtKuiHjc9jpJ6yR9rb6hNs8NN9xQWC/qdvL666/XMob58+fnanQvKa9M\n69GJiHgru31K0gFJ10paJWlTttkmSffWNUhgUDqag9heKOkPJe2RNH9Sb6yPJOX/qwIarnRAbH9K\n0ouS1kbEbyb/LFoL6IWL6LQeRZOVCojtS9UKx+aI+FFWPmZ7QfbzBZKOFz2W1qNosjKdFa1Wo7gD\nEfGdST/aIWmNpMez79trGWGDXXPNNYX1RYsW5WpVJ+mdvAveybknM12ZVaw/lfTXkn5ue29W+7pa\nwXjB9oOSDku6v54hAoNTpvXobknt/mvJX1YJGCG8kw4kEBAggYAACZwPUqNerAoVXZH25MmTteyL\n80HyOIIACQQESCAgQAIBARKYpNeo6NockjRr1qxcrd0k+6WXXiq1r3vuuaewPnv27FKPT41hJuMI\nAiQQECCBgAAJBARIICBAAqtYNWp38ZoNGzbkas8991zhtmfPns3Vilabli5dWvj4q666KjVETIMj\nCJBAQIAEAgIkVGk9ut72Udt7s6+76x8u0F9VWo9K0pMR8a36htccZ86cydWKJtjS4CfOnPdRXpmm\nDROSJrLbp2xfbD0KjLwqrUcl6WHb79jeSHd3jKIqrUe/K2mRpKVqHWG+3eZxtB5FY3XdejQijkXE\n+Yi4IOn7km4reiytR9FkZVaxCluPXuzLm1ktaV/vhwcMVpXWow/YXqpWV/dDkr5Uywgb4tVXX83V\n9uzZU7CldPvtt+dqveitW6ToYymcGFVeldajL/d+OMBw4Z10IIGAAAkEBEiYceeDVP2YRbsJbtHz\ndjIZbrdtUb3oyrVr164tva92+AhKHkcQIIGAAAkEBEggIEACAQESWMVS+xWkOXPm5Grbtm0rva/F\nixcX1i+//PJcbcuWLYXbFvX3veKKK3K1dpecLlLUVUWSJiYmcrW33367cNuqH3dpCo4gQAIBARII\nCJBAQIAE9/PjBWNjYzE+Pt63/VVV10S06sdSyj5nu+ftxbZlHz+sxsbGND4+Pu2AOYIACQQESCAg\nQEKZpg1X2P4v2/+dtR79+6x+o+09tg/a/qHty+ofLtBfZY4gv5W0PCKWqNUDa4Xtz0l6Qq3Wo38g\n6deSHqxvmL0TEbmvfu6rF/vr5DmLtrVd+FWkk23rer2DNG1AouV0dvfS7CskLZe0NatvknRvLSME\nBqhs47hZWcuf45J2Snpf0smIOJdtckT068UIKhWQrIPiUknXqdVB8ZayO6D1KJqso1WsiDgp6TVJ\nfyJptu2Lnwa+TtLRNo+h9Sgaq8wq1jzbs7PbV0q6S9IBtYLyV9lmayRtr2uQwKCUOR9kgaRNtmep\nFagXIuLHtt+VtMX2P0h6W63+vY3Uq5Wlqfr50Yu69lXXx1Kaokzr0XfUuibI1PoHatPRHRgVvJMO\nJBAQIIGAAAkzrmlDk85ZaGdYJ/+j8LudiiMIkEBAgAQCAiQQECCBgAAJBARIICBAAgEBEggIkEBA\ngAQCAiQQECCBgAAJBARIICBAQpXevM/a/tD23uxraf3DBfqrzAlTF3vznrZ9qaTdtv8t+9nfRcTW\nxGOBRivT1SQkFfXmBUZeV715I2JP9qNv2n7H9pO28xf/Fq1H0Wxd9ea1vVjSo2r16P1jSXMkfa3N\nY2k9isbqtjfvioiYyC6N8FtJ/yyayGEEddub939sL8hqVuvaIPvqHCgwCFV68/7E9jxJlrRX0t/W\nOE5gIKr05l1ey4iAIcI76UACAQESCAiQQECABAICJBAQIIGAAAkEBEggIEACAQESCAiQQECABAIC\nJBAQIIGAAAkEBEggIEACAQESCAiQ4FbjxD7tzP5Y0uHs7lxJJ/q28/7hdTXD70fEtI3a+hqQ39mx\nPR4RYwPZeY14XaOFP7GABAICJAwyIN8b4L7rxOsaIQObgwBNwJ9YQELfA2J7he1f2D5oe12/999L\ntjfaPm5736TaHNs7bb+Xff/MIMfYDdvX237N9rvZZfe+ktUb/9o61deAZA2w/0nSSkm3SnrA9q39\nHEOPPStpxZTaOkm7IuJmSbuy+01zTtJXI+JWSZ+T9OXs32kUXltH+n0EuU3SwYj4ICL+T9IWSav6\nPIaeiYifSvrVlPIqSZuy25vUujREo2TXfnkru31K0gFJ12oEXlun+h2QayX9ctL9I1ltlMyPiIns\n9keS5g9yMFXZXqhWd/89GrHXVgaT9BplF0Bt7DKh7U9JelHS2oj4zeSfNf21ldXvgByVdP2k+9dl\ntVFybNLVtxaodeHTxsku+f2ipM0R8aOsPBKvrRP9Dsibkm62faPtyyR9QdKOPo+hbjskrclur5G0\nfYBj6Up2Wb0fSDoQEd+Z9KPGv7ZO9f2NQtt3S3pK0ixJGyPim30dQA/Zfl7SMrU+6XpM0jckvSTp\nBUk3qPXJ5fsjYupEfqjZ/ryk/5D0c0kXsvLX1ZqHNPq1dYp30oEEJulAAgEBEggIkEBAgAQCAiQQ\nECCBgAAJBARI+H/QQn/4Lz8TcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3055f935c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'../fonts/saved_model_5/variables/variables'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'../fonts/saved_model_5/variables/variables'\n"
     ]
    }
   ],
   "source": [
    "classes = ['Unk'] + list(string.digits + string.ascii_uppercase)\n",
    "rec = recognizer.Recognizer('../fonts/saved_model_5')\n",
    "def predict_img(img, verbose=False):\n",
    "    img = img[np.newaxis, :, :, np.newaxis]\n",
    "    prediction = rec.predict(img)\n",
    "    if verbose:\n",
    "        print(prediction)\n",
    "    return classes[np.argmax(prediction)]\n",
    "\n",
    "def pedict_file(path, verbose=False):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return predict_img(img, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/lot1/outputs/new2/frames/1432/chars/recognized_D_960_213_24_49.jpg'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN Virtual Env",
   "language": "python",
   "name": "cnn-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
